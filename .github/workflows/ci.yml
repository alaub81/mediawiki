name: CI (lint, build, scan, e2e)

on:
  pull_request:
  push:
    branches: [main]

permissions:
  contents: read
  security-events: write  # für Trivy SARIF Upload

jobs:
  lint:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        dockerfile:
          - Dockerfile-mediawiki
          - Dockerfile-memcachephp
    steps:
      - uses: actions/checkout@v5

      - name: Hadolint
        uses: hadolint/hadolint-action@v3.3.0
        with:
          dockerfile: ${{ matrix.dockerfile }}
          config: .hadolint.yaml
          failure-threshold: warning

      - name: ShellCheck
        uses: ludeeus/action-shellcheck@2.0.0
        with:
          scandir: .
          ignore_names: "*.log\n*.sql\n"

      - name: Yamllint
        uses: ibiqlik/action-yamllint@v3
        with:
          config_file: .yamllint.yaml
          file_or_dir: ".\n"
          strict: true

  build_and_scan:
    runs-on: ubuntu-latest
    needs: lint
    strategy:
      fail-fast: false
      matrix:
        image:
          - {name: "mediawiki-custom", dockerfile: "Dockerfile-mediawiki", context: "."}
          - {name: "memcachephp", dockerfile: "Dockerfile-memcachephp", context: "."}
    steps:
      - uses: actions/checkout@v5

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3

      - name: Set up Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Docker meta
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository_owner }}/${{ matrix.image.name }}
          # Tags: PR bekommt pr-XYZ und sha; main bekommt main und sha
          tags: |
            type=ref,event=pr
            type=sha
            type=raw,value=main,enable={{is_default_branch}}

      - name: Build (amd64, für Trivy "load")
        uses: docker/build-push-action@v6
        with:
          context: ${{ matrix.image.context }}
          file: ${{ matrix.image.dockerfile }}
          platforms: linux/amd64
          load: true
          push: false
          pull: true
          cache-from: type=gha
          cache-to: type=gha,mode=max
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}

      - name: Trivy scan
        uses: aquasecurity/trivy-action@0.33.1
        with:
          scan-type: image
          image-ref: ${{ fromJSON(steps.meta.outputs.json).tags[0] }}
          format: sarif
          output: trivy-${{ matrix.image.name }}.sarif
          vuln-type: 'os,library'
          severity: 'CRITICAL,HIGH,MEDIUM'
          ignore-unfixed: true

      - name: Upload SARIF
        if: ${{ github.event.repository.private == false }}
        uses: github/codeql-action/upload-sarif@v4
        with:
          sarif_file: trivy-${{ matrix.image.name }}.sarif

  e2e:
    runs-on: ubuntu-latest
    needs: build_and_scan
    steps:
      - uses: actions/checkout@v5

      - name: Copy docker-compose.yml
        run: |
          cp docker-compose.example.yml docker-compose.yml

      - name: Write CI .env (override)
        run: |
          cat > .env.ci <<'EOF'
          TZ=Europe/Berlin
          MW_HTTP_PORT=8080

          # Database
          MARIADB_ROOT_PASSWORD=ciRootPassw0rd
          MW_DB_HOST=database
          MW_DB_PORT=3306
          MW_DB_NAME=wikidb
          MW_DB_USER=wikiuser
          MW_DB_PASS=w1k1pass
          MW_DB_ADMIN_USER=root

          # MediaWiki
          MW_CONFIG_FILE="/var/www/html/conf/LocalSettings.php"
          MW_SITENAME="Wiki CI"
          MW_LANG=de
          MW_ADMIN_USER=Admin
          MW_ADMIN_PASS=AdminPass123
          MW_SITEMAP_GENERATION=true
          MW_SITEMAP_RUN_ON_START=true
          MW_SITEMAP_IDENTIFIER=wiki
          MW_ROTTENLINKS_GENERATION=true
          MW_ROTTENLINKS_RUN_ON_START=true

          # MemcachePHP
          MEMCACHEPHP_HTTP_PORT=8097
          MEMCACHEPHP_ADMIN_USER=admin
          MEMCACHEPHP_ADMIN_PASS=supersecret
          MEMCACHEPHP_SERVERS=memcached:11211

          # E2E Tests
          E2E_PAGE_TITLE=E2E-Tagcloud-Test
          E2E_MARK=E2E_TAGCLOUD_OK
          E2E_BAD_URL=http://does-not-exist.invalid/e2e-broken
          EOF

      - name: Export CI env to shell (for compose variable substitution)
        run: |
          set -a
          . ./.env.ci
          set +a

      - name: Compose up
        run: |
          docker compose \
            -f docker-compose.yml \
            -f docker-compose.ci.yml \
            --env-file .env.ci \
            up -d --build

      - name: Wait for database (TCP-ready from mediawiki)
        shell: bash
        run: |
          # Warte aus dem MediaWiki-Container auf TCP-Port der DB (ohne externe Tools)
          docker compose exec -T -u www-data mediawiki sh -lc '
            end=$((SECONDS+120))
            until php -r "exit(@fsockopen(getenv(\"MW_DB_HOST\")?: \"database\", (int)(getenv(\"MW_DB_PORT\")?:3306))?0:1);"; do
              [ $SECONDS -ge $end ] && { echo "DB TCP not reachable"; exit 1; }
              sleep 2
            done
            echo "DB TCP reachable"
          '

      - name: (Optional) Verify DB auth if client exists
        shell: bash
        run: |
          docker compose exec -T database sh -lc '
            if command -v mysqladmin >/dev/null 2>&1; then
              mysqladmin ping -h 127.0.0.1 -u "${MARIADB_ROOT_USER:-root}" -p"${MARIADB_ROOT_PASSWORD}" --silent
            elif command -v mariadb-admin >/dev/null 2>&1; then
              mariadb-admin ping -h 127.0.0.1 -u "${MARIADB_ROOT_USER:-root}" -p"${MARIADB_ROOT_PASSWORD}" --silent
            else
              echo "No mysqladmin/mariadb-admin in image – skipping auth ping"
            fi
          '

      - name: Ensure MediaWiki is installed (install or update)
        run: |
          docker compose exec -T -u www-data mediawiki sh -lc '
            /usr/local/bin/mw-default-setup.sh
          '

      - name: Enable MW debug (wgShowExceptionDetails)
        shell: bash
        run: |
          docker compose exec -T -u www-data mediawiki bash -lc '
            set -e
            f="${MW_CONFIG_FILE:-/var/www/html/LocalSettings.php}"
            [ -f "$f" ] || { echo "::error::missing $f"; exit 1; }
            printf "\n# Debug (CI)\n\$wgShowExceptionDetails = true;\n" >> "$f"
          '

      - name: Enable intersection Extension
        shell: bash
        run: |
          docker compose exec -T -u www-data mediawiki bash -lc '
            set -e
            f="${MW_CONFIG_FILE:-/var/www/html/LocalSettings.php}"
            [ -f "$f" ] || { echo "::error::missing $f"; exit 1; }
            printf "\n# Intersection Extension\n\wfLoadExtension( 'intersection' );\n" >> "$f"
          '

      - name: Ensure Short URLs in LocalSettings.php
        shell: bash
        run: |
          # Datei im Container patchen – idempotent
          docker compose exec -T -u www-data mediawiki sh -lc '
            set -eu
            f=${MW_CONFIG_FILE:-/var/www/html/LocalSettings.php}
            [ -f "$f" ] || { echo "::error::LocalSettings.php missing"; exit 1; }

            # $wgScriptPath = "";
            if grep -q "^\$wgScriptPath" "$f"; then
              sed -i '\''s#^\$wgScriptPath\s*=.*#\$wgScriptPath = "";#'\'' "$f"
            else
              # vor dem PHP-Schluss einfügen, falls vorhanden – sonst ans Ende
              if grep -q "^?>" "$f"; then
                sed -i '\''s#^?>#\$wgScriptPath = "";\n?>#'\'' "$f"
              else
                printf "\n\$wgScriptPath = \"\";\n" >> "$f"
              fi
            fi

            # $wgArticlePath = "/wiki/$1";
            if grep -q "^\$wgArticlePath" "$f"; then
              sed -i '\''s#^\$wgArticlePath\s*=.*#\$wgArticlePath = "/wiki/\$1";#'\'' "$f"
            else
              if grep -q "^?>" "$f"; then
                sed -i '\''s#^?>#\$wgArticlePath = "/wiki/\$1";\n?>#'\'' "$f"
              else
                printf "\n\$wgArticlePath = \"/wiki/\\\$1\";\n" >> "$f"
              fi
            fi
          '

      - name: generate sitemap
        run: |
          docker compose exec -T mediawiki sh -lc '
            set -e
            /usr/local/bin/generate-sitemap.sh
          '

      - name: E2E - check (API)
        run: |
          # .env einlesen (falls vorhanden)
          [ -f .env.ci ] && { set -a; . ./.env.ci; set +a; }
          for i in $(seq 1 30); do
            if curl -fsS "http://localhost:${MW_HTTP_PORT:-8080}/api.php?action=query&meta=siteinfo&format=json" | grep -q '"query"'; then
              echo "MediaWiki API OK"; exit 0
            fi
            sleep 3
          done
          echo "MediaWiki API not reachable"
          docker compose logs --no-color > compose-logs.txt || true
          exit 1

      - name: E2E - check sitemap redirect and target
        shell: bash
        run: |
          # ENV laden, ohne PATH zu zerlegen
          [ -f .env.ci ] && { set -a; . ./.env.ci; set +a; }

          : "${MW_HTTP_PORT:=8080}"
          BASE="${MW_SERVER_URL:-http://localhost:${MW_HTTP_PORT}}"

          echo "[e2e] Expect: ${BASE}/sitemap.xml redirects (301) and final target returns 200"

          ok=0
          for i in $(seq 1 40); do
            # 1) MW-API erreichbar?
            if ! curl -fsS "${BASE%/}/api.php?action=query&meta=siteinfo&format=json" | grep -q '"query"'; then
              sleep 3; continue
            fi

            # 2) Nur den ersten Status von /sitemap.xml prüfen (ohne -L)
            first_code="$(curl -sS -o /dev/null -w '%{http_code}' -I "${BASE%/}/sitemap.xml" || echo)"
            # Standard: 301. Wenn du 302 auch akzeptieren willst, ersetze die nächste Zeile durch:
            # [ "$first_code" = "301" ] || [ "$first_code" = "302" ]
            [ "$first_code" = "301" ] || { sleep 3; continue; }

            # 3) Finalen Code nach Follow-Redirect prüfen (mit -L)
            final_code="$(curl -sS -o /dev/null -w '%{http_code}' -IL "${BASE%/}/sitemap.xml" || echo)"
            if [ "$final_code" = "200" ]; then
              echo "[e2e] OK: first=$first_code, final=$final_code"
              ok=1
              break
            fi
            sleep 3
          done

          if [ "$ok" != "1" ]; then
            echo "::error::Sitemap redirect/target check failed"
            echo "[debug] HEAD /sitemap.xml (no follow):"
            curl -v -sI "${BASE%/}/sitemap.xml" || true
            echo "[debug] HEAD /sitemap.xml (follow -L):"
            curl -v -sIL "${BASE%/}/sitemap.xml" || true
            echo "[debug] MW api siteinfo:"
            curl -sS "${BASE%/}/api.php?action=query&meta=siteinfo&format=json" | head -c 400 || true
            exit 1
          fi

      - name: E2E — short URLs rewrite
        shell: bash
        run: |
          [ -f .env.ci ] && { set -a; . ./.env.ci; set +a; }
          : "${MW_HTTP_PORT:=8080}"
          BASE="http://localhost:${MW_HTTP_PORT}"
          for i in $(seq 1 30); do
            H="$(curl -fsSI "${BASE}/index.php/Special:Version" || true)"
            echo "$H" | grep -qiE '^HTTP/.* 301 ' || { sleep 2; continue; }
            echo "$H" | grep -qiE '^Location: .*/wiki/(Special|Spezial):Version\s*$' && { echo "Short URLs OK"; exit 0; }
            sleep 2
          done
          echo "::error::Short URL redirect failed"
          curl -v -sI "${BASE}/index.php/Special:Version" || true
          exit 1

      - name: E2E — X-Content-Type-Options on /images
        shell: bash
        run: |
          [ -f .env.ci ] && { set -a; . ./.env.ci; set +a; }
          : "${MW_HTTP_PORT:=8080}"
          BASE="http://localhost:${MW_HTTP_PORT}"
          docker compose exec -T -u www-data mediawiki sh -lc 'printf test > /var/www/html/images/ci.txt'
          curl -fsSI "${BASE}/images/ci.txt" | grep -qi '^X-Content-Type-Options: *nosniff' \
            && echo "nosniff OK" \
            || { echo "::error::nosniff header missing on /images/ci.txt"; exit 1; }
          docker compose exec -T -u www-data mediawiki rm -f /var/www/html/images/ci.txt

      - name: E2E — which extensions loaded
        shell: bash
        run: |
          [ -f .env.ci ] && { set -a; . ./.env.ci; set +a; }
          : "${MW_HTTP_PORT:=8080}"
          : "${E2E_EXPECT_EXTENSIONS:=}"   # leer = nur auflisten
          JSON="$(curl -fsS "http://localhost:${MW_HTTP_PORT}/api.php?action=query&meta=siteinfo&siprop=extensions&format=json")"
          if [ -z "$E2E_EXPECT_EXTENSIONS" ]; then
            echo "$JSON" | grep -o '"name":"[^"]*"' | sed 's/.*:"//;s/"$//' | sort -u | sed 's/^/ - /'
            exit 0
          fi
          fail=0
          for ext in $E2E_EXPECT_EXTENSIONS; do
            echo "$JSON" | grep -q "\"name\":\"$ext\"" \
              && echo "✓ $ext" \
              || { echo "::error::Extension not loaded: $ext"; fail=1; }
          done
          exit $fail

      - name: E2E — all extensions are loaded
        shell: bash
        run: |
          # .env.ci sicher laden ohne PATH zu zerstören
          if [ -f .env.ci ]; then ORIG_PATH="$PATH"; set -a; . ./.env.ci; set +a; export PATH="$ORIG_PATH"; fi
          : "${MW_HTTP_PORT:=8080}"
          : "${E2E_EXPECT_EXTENSIONS:=$(docker compose exec -T mediawiki printenv MW_EXTRA_EXTENSIONS | tr -d '\r')}"
          echo "E2E_EXPECT_EXTENSIONS: $E2E_EXPECT_EXTENSIONS"

          # Normalisierer: lower + nur [a-z0-9]
          norm() { printf '%s' "$1" | tr '[:upper:]' '[:lower:]' | tr -cd '[:alnum:]'; }

          # API holen und alle Extension-"name"-Felder extrahieren
          JSON="$(curl -fsS "http://localhost:${MW_HTTP_PORT}/api.php?action=query&meta=siteinfo&siprop=extensions&format=json")"
          API_NAMES="$(printf '%s' "$JSON" | grep -o '"name":"[^"]*"' | cut -d: -f2- | tr -d '"' )"

          # In Normalform umwandeln (eine pro Zeile)
          API_NORM=""
          while IFS= read -r n; do API_NORM="${API_NORM}$(norm "$n")"$'\n'; done <<<' '"$API_NAMES"

          fail=0
          for ext in $E2E_EXPECT_EXTENSIONS; do
            [ -z "$ext" ] && continue
            want="$(norm "$ext")"
            if printf '%s\n' "$API_NORM" | grep -qx "$want"; then
              echo "✓ $ext"
            else
              echo "::error::Extension not loaded (by name): $ext"
              fail=1
            fi
          done
          exit $fail

      - name: E2E — all skins are loaded
        shell: bash
        run: |
          # .env.ci sicher laden ohne PATH zu zerstören
          if [ -f .env.ci ]; then ORIG_PATH="$PATH"; set -a; . ./.env.ci; set +a; export PATH="$ORIG_PATH"; fi
          : "${MW_HTTP_PORT:=8080}"
          : "${E2E_EXPECT_SKINS:=$(docker compose exec -T mediawiki printenv MW_EXTRA_SKINS | tr -d '\r')}"
          [ -n "$E2E_EXPECT_SKINS" ] || { echo "No E2E_EXPECT_SKINS defined, skipping"; exit 0; }

          # 1) Helfer zuerst definieren
          norm(){ printf '%s' "$1" | tr '[:upper:]' '[:lower:]' \
                  | sed -E 's/[ _]+/-/g; s/[^a-z0-9-]+//g'; }
          to_code(){
            n="$(norm "$1")"
            case "$n" in
              vector2022|vector-2022) echo "vector-2022" ;;
              minervaneue|minerva)    echo "minerva" ;;
              monobook)               echo "monobook" ;;
              timeless)               echo "timeless" ;;
              deskmessmirrored|desk*) echo "deskmessmirrored" ;;
              cologneblue|cologne-blue) echo "cologneblue" ;;
              *) echo "$n" ;;
            esac
          }

          # 2) Erwartung aus MW_SKINS bauen (eine Zeile pro Code)
          WANT=""
          for s in $E2E_EXPECT_SKINS; do
            c="$(to_code "$s")"
            [ -n "$c" ] && WANT="${WANT}${c}\n"
          done

          # 3) Installierte/geladene Skins aus der API – WICHTIG: mit \n pro Eintrag!
          JSON="$(curl -fsS "http://localhost:${MW_HTTP_PORT:-8080}/api.php?action=query&meta=siteinfo&siprop=skins&format=json")"
          API_CODES="$(
            printf '%s' "$JSON" \
            | grep -o '"code":"[^"]*"' | cut -d'"' -f4 \
            | while IFS= read -r x; do printf '%s\n' "$(norm "$x")"; done
          )"

          # 4) Vergleichen (exakte Zeilen-Treffer)
          fail=0
          printf '%b' "$WANT" | while IFS= read -r need; do
            [ -z "$need" ] && continue
            if printf '%s\n' "$API_CODES" | grep -qx "$need"; then
              echo "✓ skin loaded: $need"
            else
              echo "::error::skin not loaded: $need"
              fail=1
            fi
          done
          exit $fail

      - name: E2E — create test page
        shell: bash
        run: |
          # .env.ci sicher laden ohne PATH zu zerstören
          if [ -f .env.ci ]; then ORIG_PATH="$PATH"; set -a; . ./.env.ci; set +a; export PATH="$ORIG_PATH"; fi
          : "${E2E_PAGE_TITLE:=E2E-Tagcloud-Test}"
          : "${E2E_MARK:=E2E_TAGCLOUD_OK}"
          : "${E2E_BAD_URL:=http://does-not-exist.invalid/e2e-broken}"

          docker compose exec -T -u www-data mediawiki bash -lc '
            set -e
            cat >/tmp/e2e-page.txt <<EOF
          == E2E ==
          Marker: '"$E2E_MARK"'

          <tagcloud></tagcloud>

          Broken link: ['"$E2E_BAD_URL"' E2E-Broken-Link]
          EOF
          # Seite anlegen/überschreiben (ohne Login, via Maintenance)
          php maintenance/run.php edit --summary "e2e create" --no-rc "'"$E2E_PAGE_TITLE"'" < /tmp/e2e-page.txt
          '

      - name: E2E — memcached reachable from mediawiki
        shell: bash
        run: |
          docker compose exec -T mediawiki bash -lc '
            set -e
            exec 3<>/dev/tcp/memcached/11211
            printf "version\r\n" >&3
            read -r LINE <&3
            echo "$LINE" | grep -q "^VERSION" && echo "memcached OK" || { echo "$LINE"; exit 1; }
            exec 3>&- 3<&-
          '

      - name: E2E — siteinfo sanity
        shell: bash
        run: |
          [ -f .env.ci ] && { set -a; . ./.env.ci; set +a; }
          : "${MW_HTTP_PORT:=8080}"
          OUT="$(curl -fsS "http://localhost:${MW_HTTP_PORT}/api.php?action=query&meta=siteinfo&format=json")"
          echo "$OUT" | grep -q '"server":"' || { echo "::error::no server in siteinfo"; exit 1; }
          [ -n "${MW_SITENAME:-}" ] && echo "$OUT" | grep -q "\"sitename\":\"${MW_SITENAME}\"" || true

      - name: E2E — sitemap index is recent
        shell: bash
        run: |
          [ -f .env.ci ] && { set -a; . ./.env.ci; set +a; }
          : "${MW_SITEMAP_IDENTIFIER:=wiki}"
          p="${MW_SITEMAP_URLPATH:-}"

          # FS-Verzeichnis bestimmen: "" -> /var/www/html ; "sitemap/" -> /var/www/html/sitemap
          norm_p="$( [ -n "$p" ] && printf '%s' "$p" | sed -E 's#^/+##; s#/+$##' || true )"
          if [ -n "$norm_p" ]; then
            FS_DIR="/var/www/html/${norm_p}"
          else
            FS_DIR="/var/www/html"
          fi
          IDX="${FS_DIR}/sitemap-index-${MW_SITEMAP_IDENTIFIER}.xml"

          echo "[e2e] Expect index at: $IDX"

          # 1x generieren, falls noch nicht da (idempotent)
          docker compose exec -T mediawiki sh -lc '
            if [ ! -s "'"$IDX"'" ] && command -v /usr/local/bin/generate-sitemap.sh >/dev/null 2>&1; then
              /usr/local/bin/generate-sitemap.sh || true
            fi
          '

          # prüfen mit Retry
          ok=0
          for i in $(seq 1 20); do
            if docker compose exec -T mediawiki sh -lc '[ -s "'"$IDX"'" ]'; then
              age="$(docker compose exec -T mediawiki sh -lc 'now=$(date +%s); \
                mt=$(stat -c %Y "'"$IDX"'" 2>/dev/null || stat -f %m "'"$IDX"'"); echo $((now-mt))')"
              echo "sitemap age: ${age}s"
              if [ "${age:-999999}" -le 900 ]; then  # <= 15 min
                ok=1; break
              fi
            fi
            sleep 3
          done

          if [ "$ok" != "1" ]; then
            echo "::error::missing or stale sitemap index: $IDX"
            echo "[debug] ls target dir:"
            docker compose exec -T mediawiki sh -lc 'ls -l '"$(dirname "$IDX")"' || true'
            exit 1
          fi

      - name: E2E — Elasticsearch healthy (yellow/green)
        shell: bash
        run: |
          set -euo pipefail
          # bis zu ~3 Minuten warten (40 * 5s)
          for i in $(seq 1 40); do
            if docker compose exec -T elasticsearch sh -lc \
              "curl -fsS --max-time 4 'http://elasticsearch:9200/_cat/health?h=status' | grep -Eq 'yellow|green'"; then
              echo "✓ Elasticsearch healthy"
              exit 0
            fi
            sleep 5
          done
          echo "::error::Elasticsearch wurde nicht healthy (timeout)"
          echo "[debug] /_cat/health:"
          docker compose exec -T elasticsearch sh -lc "wget -qO- 'http://localhost:9200/_cat/health?v'"
          echo "[debug] Plugins:"
          docker compose exec -T elasticsearch sh -lc 'bin/elasticsearch-plugin list || true'
          exit 1

      - name: E2E — Bootstrap Cirrus index (script)
        shell: bash
        run: |
          set -euo pipefail
          docker compose exec -T mediawiki sh -lc '
            /usr/local/bin/generate-elasticindex.sh
          '

      - name: E2E — Cirrus index present
        shell: bash
        run: |
          set -euo pipefail
          # Werte aus .env.ci sauber laden (falls vorhanden)
          if [ -f .env.ci ]; then ORIG_PATH="$PATH"; set -a; . ./.env.ci; set +a; export PATH="$ORIG_PATH"; fi
          DB="${MW_DB_NAME:-wikidb}"
          for i in $(seq 1 60); do
            if docker compose exec -T elasticsearch sh -lc \
              "curl -fsS 'http://localhost:9200/_cat/indices?h=index' | grep -q '${DB}_content'"; then
              echo "✓ Index ${DB}_content vorhanden"; exit 0; fi
            sleep 3
          done
          echo "::error::Cirrus content-index nicht gefunden"; exit 1

      - name: E2E — CirrusSearch wired
        shell: bash
        run: |
          set -euo pipefail
          # .env.ci laden, ohne PATH kaputt zu machen
          if [ -f .env.ci ]; then ORIG_PATH="$PATH"; set -a; . ./.env.ci; set +a; export PATH="$ORIG_PATH"; fi
          : "${MW_HTTP_PORT:=8080}"
          BASE="http://localhost:${MW_HTTP_PORT}"

          # 1) Backend ist CirrusSearch?
          BACKEND="$(docker compose exec -T mediawiki sh -lc 'printf "%s\n" "echo \$wgSearchType, PHP_EOL;" \
            | php maintenance/run.php eval')"
          if [ "$BACKEND" != "CirrusSearch" ]; then
            echo "::error::wgSearchType ist '$BACKEND', erwartet 'CirrusSearch'"
            exit 1
          fi
          echo "✓ wgSearchType=CirrusSearch"

          # 2) Cirrus-API erreichbar?
          if ! curl -fsS "${BASE}/api.php?action=cirrus-config-dump&format=json" >/dev/null; then
            echo "::error::cirrus-config-dump nicht erreichbar"
            exit 1
          fi
          echo "✓ cirrus-config-dump erreichbar"

          # 3) Optionaler Smoke-Test (morelike) – nicht kritisch
          if curl -fsS "${BASE}/api.php?action=query&list=search&srsearch=morelike:Hauptseite&srlimit=3&format=json" \
              | grep -q '"search":\[' ; then
            echo "✓ morelike liefert JSON"
          else
            echo "::warning::morelike ergab keine Treffer (Index evtl. noch im Aufbau) – kein harter Fehler"
          fi

      - name: E2E — homepage renders (no exceptions)
        shell: bash
        run: |
          set -Eeuo pipefail

          # ENV laden (optional)
          [ -f .env.ci ] && { P="$PATH"; set -a; . ./.env.ci; set +a; PATH="$P"; }

          : "${MW_HTTP_PORT:=8080}"
          : "${MW_SERVER_URL:=http://localhost:${MW_HTTP_PORT}}"
          : "${E2E_PAGE_TITLE:=E2E-Tagcloud-Test}"
          : "${E2E_MARK:=E2E_TAGCLOUD_OK}"

          url="${MW_SERVER_URL%/}/wiki/${E2E_PAGE_TITLE// /_%20}"
          echo "[e2e] GET $url"

          tmpdir="$(mktemp -d)"
          code="$(curl -sS --fail-with-body -L -D "$tmpdir/headers" -o "$tmpdir/body" -w '%{http_code}' "$url" || true)"
          echo "[e2e] HTTP $code"

          # 1) HTTP-Fehlercodes abfangen
          if [ -z "${code:-}" ] || [ "$code" -ge 500 ]; then
            echo "::error::Server error (HTTP $code)"
            sed -n '1,80p' "$tmpdir/headers" || true
            tail -n 120 "$tmpdir/body" || true
            docker compose logs --no-color --tail 200 mediawiki || true
            exit 1
          fi

          # 2) Exception-Marker im Body erkennen (auch wenn HTTP 200)
          if grep -qiE 'MediaWiki internal error|Original exception|Fatal error|Backtrace' "$tmpdir/body"; then
            echo "::error::Exception markers found in response body"
            sed -n '1,80p' "$tmpdir/headers" || true
            # Zeige einen Body-Ausschnitt um die erste Fundstelle
            line="$(grep -niE 'MediaWiki internal error|Original exception|Fatal error|Backtrace' "$tmpdir/body" | \
              head -n1 | cut -d: -f1 || true)"
            if [ -n "$line" ]; then
              start=$(( line>40 ? line-40 : 1 )); end=$(( line+120 ))
              sed -n "${start},${end}p" "$tmpdir/body" || true
            else
              tail -n 120 "$tmpdir/body" || true
            fi
            docker compose logs --no-color --tail 200 mediawiki || true
            exit 1
          fi

          # 3) Erwartungstext prüfen (einfacher Smoke-Test)
          if ! grep -qi -- "$E2E_MARK" "$tmpdir/body"; then
            echo "::error::Expected text not found: $E2E_MARK"
            sed -n '1,60p' "$tmpdir/headers" || true
            head -n 120 "$tmpdir/body" || true
            exit 1
          fi

          echo "[e2e] OK — homepage renders and contains: $E2E_MARK"

      - name: E2E — RottenLinks lists the broken URL
        shell: bash
        run: |
          set -Eeuo pipefail
          [ -f .env.ci ] && { P="$PATH"; set -a; . ./.env.ci; set +a; PATH="$P"; }

          : "${MW_HTTP_PORT:=8080}"
          : "${MW_SERVER_URL:=http://localhost:${MW_HTTP_PORT}}"
          : "${E2E_BAD_URL:=http://does-not-exist.invalid/e2e-broken}"

          # 1) Generierung anstoßen (nimm dein Script, sonst Fallback: Jobs laufen lassen)
          if docker compose exec -T mediawiki test -x /usr/local/bin/generate-rottenlinks.sh; then
            docker compose exec -T mediawiki /usr/local/bin/generate-rottenlinks.sh || true
          else
            docker compose exec -T -u www-data mediawiki php maintenance/run.php runJobs --maxjobs=200 || true
          fi

          # 2) Spezialseite „RottenLinks“ pollen und nach URL suchen
          base="${MW_SERVER_URL%/}"
          rl_url="$base/wiki/Spezial:RottenLinks"
          ok=0
          for i in $(seq 1 10); do
            body="$(curl -fsSL "$rl_url" || true)"
            if printf '%s' "$body" | grep -Fq "$E2E_BAD_URL"; then
              echo "[e2e] OK — RottenLinks lists $E2E_BAD_URL"
              ok=1; break
            fi
            sleep 3
          done
          if [ "$ok" != "1" ]; then
            echo "::error::Broken URL not found on Spezial:RottenLinks"
            echo "[debug] first 120 lines:"; printf '%s' "${body:-}" | sed -n '1,120p'
            exit 1
          fi

      - name: E2E — memcachephp UI
        shell: bash
        run: |
          # .env einlesen (falls vorhanden)
          [ -f .env.ci ] && { set -a; . ./.env.ci; set +a; }
          : "${MEMCACHEPHP_HTTP_PORT:=8097}"
          : "${MEMCACHEPHP_ADMIN_USER:=admin}"
          : "${MEMCACHEPHP_ADMIN_PASS:=supersecret}"

          BASE="http://localhost:${MEMCACHEPHP_HTTP_PORT}/"

          echo "[e2e] Checking ${BASE} with basic auth user=${MEMCACHEPHP_ADMIN_USER}"

          for i in $(seq 1 30); do
            if curl -fsS -u "${MEMCACHEPHP_ADMIN_USER}:${MEMCACHEPHP_ADMIN_PASS}" "${BASE}" \
              | grep -Eiq 'memcache|server stats|slabs'; then
              echo "MEMCACHEPHP OK"
              exit 0
            fi
            sleep 3
          done

      - name: E2E — MemcachePHP hinter /memcache Reverse Proxy
        shell: bash
        run: |
          [ -f .env.ci ] && { set -a; . ./.env.ci; set +a; }

          : "${MW_HTTP_PORT:=8080}"
          : "${MEMCACHEPHP_ADMIN_USER:=admin}"
          : "${MEMCACHEPHP_ADMIN_PASS:=supersecret}"
          BASE="${MW_SERVER_URL:-http://localhost:${MW_HTTP_PORT}}"
          base="${BASE%/}"

          echo "[e2e] expect: /memcache, /mcui, /memcacheui redirect -> /memcacheui/ (301) and proxied /memcacheui/ final 200"

          fail() { echo "::error::$*"; exit 1; }

          get_path_from_location() {
            curl -sSI "$1" \
              | awk 'BEGIN{IGNORECASE=1} /^Location:/{print $2; exit}' \
              | tr -d '\r' \
              | sed -E 's#^[a-zA-Z][a-zA-Z0-9+.-]*://[^/]*##'
          }

          tries=40

          # 1) /memcache -> /memcacheui/
          ok=0
          for i in $(seq 1 $tries); do
            code="$(curl -sS -o /dev/null -w '%{http_code}' -I "$base/memcache")" || true
            { [ "$code" = "301" ] || [ "$code" = "302" ]; } || { sleep 3; continue; }
            path="$(get_path_from_location "$base/memcache")"
            case "$path" in */memcacheui/) ok=1;; *) sleep 3;; esac
            [ "$ok" = 1 ] && break
          done
          [ "$ok" = 1 ] || fail "/memcache did not redirect to /memcacheui/"

          # 2) /mcui -> /memcacheui/
          ok=0
          for i in $(seq 1 $tries); do
            code="$(curl -sS -o /dev/null -w '%{http_code}' -I "$base/mcui")" || true
            { [ "$code" = "301" ] || [ "$code" = "302" ]; } || { sleep 3; continue; }
            path="$(get_path_from_location "$base/mcui")"
            case "$path" in */memcacheui/) ok=1;; *) sleep 3;; esac
            [ "$ok" = 1 ] && break
          done
          [ "$ok" = 1 ] || fail "/mcui did not redirect to /memcacheui/"

          # 3) /memcacheui (ohne Slash) -> /memcacheui/
          ok=0
          for i in $(seq 1 $tries); do
            code="$(curl -sS -o /dev/null -w '%{http_code}' -I "$base/memcacheui")" || true
            { [ "$code" = "301" ] || [ "$code" = "302" ]; } || { sleep 3; continue; }
            path="$(get_path_from_location "$base/memcacheui")"
            case "$path" in */memcacheui/) ok=1;; *) sleep 3;; esac
            [ "$ok" = 1 ] && break
          done
          [ "$ok" = 1 ] || fail "/memcacheui did not redirect to /memcacheui/"

          # 4) Proxied Ziel /memcacheui/ (mit Basic Auth) -> final 200
          ok=0
          for i in $(seq 1 $tries); do
            final="$(curl -sS -o /dev/null -w '%{http_code}' -IL -u "$MEMCACHEPHP_ADMIN_USER:$MEMCACHEPHP_ADMIN_PASS" \
              "$base/memcacheui/")" || true
            [ "$final" = "200" ] && { ok=1; break; }
            sleep 3
          done
          [ "$ok" = 1 ] || fail "proxied /memcacheui/ not returning 200 (got $final)"

          # 5) Content-Sanity-Check ohne Broken-Pipe
          html="$(curl -fsS -u "$MEMCACHEPHP_ADMIN_USER:$MEMCACHEPHP_ADMIN_PASS" "$base/memcacheui/")" || {
            echo "::error::failed to fetch /memcacheui/ content"; exit 1; }

          # Breiteres Pattern: Memcache(d), phpMemcache(d)Admin, Server Stats/Slabs/Items
          if printf '%s' "$html" | grep -Ei '(memcache(d)?|phpmemcache(d)?admin|server[[:space:]-]?stats|slabs|items)' >/dev/null; then
            echo "[e2e] OK"
          else
            echo "::error::unexpected content at /memcacheui/"
            # Debug-Ausschnitt zeigen
            printf '%s\n' "$html" | head -n 80
            exit 1
          fi

      - name: Show logs on failure
        if: failure()
        run: |
          sed -n '1,400p' compose-logs.txt || true
          docker compose ps || true

      - name: Tear down
        if: always()
        run: docker compose down -v
